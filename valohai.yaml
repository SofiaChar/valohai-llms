- step:
    name: train-torchrun
    image: sofiiavalohai/valohai-llms:v1.5
    environment: staging-aws-eu-west-1-p3-8xlarge
    command:
      - pip install valohai-utils
      - torchrun --nproc-per-node=4 train-torchrun.py {parameters}
    parameters:
      - name: model-ckpt
        default: "facebook/bart-large-cnn"
      - name: output-dir
        default: "bart-large-cnn"
      - name: batch-size
        default: 1
      - name: num-epochs
        default: 1
      - name: warmup-steps
        default: 500
      - name: evaluation-steps
        default: 500
    inputs:
      - name: dataset
        default:
          - s3://dd-sample-bucket/llm-example/train.json
          - s3://dd-sample-bucket/llm-example/val.json

- step:
    name: train-accelerator
    image: sofiiavalohai/valohai-llms:v1.5
    environment: staging-aws-eu-west-1-p3-8xlarge
    command:
      - pip install accelerate evaluate absl-py rouge-score
      - accelerate config
      - accelerate test
      - python -m accelerate.commands.launch --num_processes=4 train-accelerator.py

- step:
    name: train-accelerator-uni
    image: sofiiavalohai/valohai-llms:v1.5
    environment: staging-aws-eu-west-1-p3-8xlarge
    command:
      - pip install accelerate evaluate absl-py rouge-score
      - python -m accelerate.commands.launch --num_processes=4 train-accelerator-unified.py {parameters}
    parameters:
      - name: model-ckpt
        default: "facebook/bart-large-cnn"
      - name: output-dir
        default: "bart-large-cnn"
      - name: batch-size
        default: 1
      - name: num-epochs
        default: 1
      - name: warmup-steps
        default: 500
      - name: evaluation-steps
        default: 500
    inputs:
      - name: dataset
        default:
          - s3://dd-sample-bucket/llm-example/train.json
          - s3://dd-sample-bucket/llm-example/val.json

- step:
    name: train-task
    image: sofiiavalohai/valohai-llms:v1.5
    environment: staging-aws-eu-west-1-p3-8xlarge
    command:
      - pip install accelerate evaluate absl-py rouge-score
      - python train-task-new.py {parameters}
    environment-variables:
      - name: VH_DOCKER_NETWORK
        default: host
    parameters:
      - name: model-ckpt
        default: "facebook/bart-large-cnn"
      - name: output-dir
        default: "bart-large-cnn"
      - name: batch-size
        default: 1
      - name: num-epochs
        default: 1
      - name: warmup-steps
        default: 500
      - name: evaluation-steps
        default: 500
    inputs:
      - name: dataset
        default:
          - s3://dd-sample-bucket/llm-example/train.json
          - s3://dd-sample-bucket/llm-example/val.json
          -
- task:
    step: train-task
    name: task 5 random
    type: distributed
    execution-count: 4
    maximum-queued-executions: 4

- step:
    name: connect
    image: python:3.9
    command:
      - pip install --upgrade pip
      - pip install torch
      - pip install sentence_transformers
      - pip install chromadb
      - pip install langchain
      - pip install transformers
      - python stuff/set_up.py
- step:
    name: test-dist-mnist
    image:  pytorch/pytorch:1.11.0-cuda11.3-cudnn8-runtime
    environment: staging-aws-eu-west-1-p3-8xlarge
    command:
      - pip install -r requirements.txt --disable-pip-version-check -q
      - python dist-mnist.py
    environment-variables:
      - name: VH_DOCKER_NETWORK
        default: host
- step:
    name: gpt2-convai
    image: python:3.9
    command:
      - pip install --upgrade pip
      - pip install torch
      - pip install sentence_transformers
      - pip install chromadb
      - pip install langchain
      - pip install transformers
      - pip install matplotlib
      - pip install datasets
      - pip install nltk
      - pip install py7zr
      - pip install accelerate -U
      - python finetuned-gpt2-convai.py